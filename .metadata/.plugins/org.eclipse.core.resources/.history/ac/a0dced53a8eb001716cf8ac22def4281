package com.locdata.scraper.main;

import java.io.IOException;
import java.net.MalformedURLException;
import java.net.SocketTimeoutException;
import java.util.Date;
import java.util.LinkedList;
import java.util.Queue;

import org.jsoup.HttpStatusException;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;

public final class ScraperLogic {
	
	private ScraperLogic() {};
	
	public static Queue<String> queue = new LinkedList<String>();
	public static Queue<String> _200OkQueue = new LinkedList<String>();
 	
	public static class Scraper{
		
		public Document fetchHtmlContents(String url){

			try {
				if(url == null || url.isEmpty() || url.equals("null")) return null; 
				
				Document doc = Jsoup.connect(url)
						.userAgent(
								"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.108 Safari/537.36")
						.timeout(100000)
						.maxBodySize(0)
						.followRedirects(false)
						.ignoreHttpErrors(false)
						.get();
				
				Thread.sleep(1000);
				
				return doc;
				
			} catch(SocketTimeoutException timeout){
				
	            System.out.println(timeout.getMessage()  + "On Error " + ScraperLogic.class + " ::: IOException on URL fetch" + new Date().toString());
	            
	            queue.add(url);
	            System.out.println(" Added url to the queue ");
			}catch(HttpStatusException httpEror){
				
	            System.out.println(httpEror.getMessage() + " <:::> " + ScraperLogic.class + " ::: response is not OK and HTTP response errors are not ignored" + new Date().toString());
	            queue.add(url);
	            System.out.println(" Added url to the queue ");
			}catch(MalformedURLException malformedexception) {
				
				System.out.println(malformedexception.getMessage() + "On Error " + ScraperLogic.class + " ::: request URL is not a HTTP or HTTPS URL");
				queue.add(url);
	            System.out.println(" Added url to the queue ");
			} catch (IOException | InterruptedException e) {
				
	            System.out.println(e.getMessage() + "On Error " + ScraperLogic.class + " ::: IOException on URL fetch" + new Date().toString());
	            queue.add(url);
	            System.out.println(" Added url to the queue ");
			}
			return null;
		}
	}
}